{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This project is focus on classifying the resume dataset provided by [Marti Palan](https://www.kaggle.com/datasets/maitrip/resumes) and [Hend Labib](https://www.kaggle.com/code/hendlabib12/resume-extraction/data)from kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. [RESUME CLEAN & ADD SKILLS](https://github.com/xilin-tian/Resume_Classification/blob/main/jupyter%20notebook/RESUME_CLEAN_%26_ADD_SKILLS_XilinTian.ipynb)\n",
    "\n",
    "In this notebook, I focused on clean the resume dataset by using pandas, droped the NaN rows and columns, then reseted the index. After finishing the cleaning, I added the 'skills' columns to that dataset and filled in the score for each resume, which is if the resume contains the skill in that column, it result one in the table, otherwise is zero. Then I saved the dataset as a [csv](https://github.com/xilin-tian/Resume_Classification/blob/main/original%20data%20and%20result%20csv/resume_add_skills.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. [SIMPLE MATCH & MACHINE LEARNING](https://github.com/xilin-tian/Resume_Classification/blob/main/jupyter%20notebook/SIMPLE_MATCH_%26_MACHINE_LEARNING.ipynb)\n",
    "\n",
    "By imported the csv file that I got in the first notebook, I first used the [Sørensen–Dice coefficient (Dice similarity coefficient)](https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient) to calculate the similarity score by setting the TP(True Positive) as the original resume and compared resume both got 1 for the same skill, FP(False Positive) as the original resume and compared resume both got 0 for the same skill, FN(False Negative) as the score of the original resume are not equal to the score of the compared resume. Then listed the ten highest scoring resumes\n",
    "\n",
    "Secondly, I extract the Category as the label and apply K-means clustering and KNN (for k = 30) on the dataset, however, the accuracy for both algorithms are not good, 1.45% and 13.41% correspodingly. Thus, the resume dataset need more deeper cleaning and remove the noise to increase the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. [NLP AND SPACY](https://github.com/xilin-tian/Resume_Classification/blob/main/jupyter%20notebook/NLP_AND_SPACY.ipynb)\n",
    "\n",
    "In this notebook, I mainly used spacy to achieve my goal. First I loaded the resume dataset csv in the first notebook, then I wanted to delete the \\x and \\n in the resume so that I use re.sub to accomplish my goal, then use the first resume as the sample resume and pick 30 other resumes from different Categories, apply spacy.similarity to get the 'score_Version_1' column and repeat these step on the resumes after removing the stopwords to get 'score_Version_2' column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. [Extract SKILLS](https://github.com/xilin-tian/Resume_Classification/blob/main/jupyter%20notebook/EXTRACT_SKILLS.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
